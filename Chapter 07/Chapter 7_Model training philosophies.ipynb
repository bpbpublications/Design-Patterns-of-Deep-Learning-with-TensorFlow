{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c86a7c5",
   "metadata": {},
   "source": [
    "#### Chapter 7: Model training Philosophies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafec76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,MaxPooling2D,Dropout,Normalization\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d874b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43220c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX,trainy,epochs=20,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a979b25",
   "metadata": {},
   "source": [
    "##### Fitting model after normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the train and test sets\n",
    "trainX_norm = trainX/255\n",
    "testX_norm = testX/255\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX_norm.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX_norm.shape, testy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2441cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX_norm,trainy,epochs=20,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561c7fb",
   "metadata": {},
   "source": [
    "#### Normalising using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an image data generator\n",
    "datagenerator = ImageDataGenerator(rescale=1./255,)\n",
    "# Defining train generator\n",
    "train_iterator = datagenerator.flow(trainX, trainy, batch_size=64)\n",
    "# Defining validation generator\n",
    "val_iterator = datagenerator.flow(testX, testy, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e571ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_iterator,epochs=20,validation_data=val_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d559c",
   "metadata": {},
   "source": [
    "#### ImageDataGenerator with Z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4074ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator with Z-score normalization\n",
    "mean = 0.5\n",
    "Std = 0.5\n",
    "datagenerator = ImageDataGenerator(rescale= (mean/255), (std/255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefcf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator with log-normalization\n",
    "import numpy as np\n",
    "def log_normalise(x):\n",
    "    return np.log(x+1)\n",
    "datagenerator = ImageDataGenerator(preprocessing_function = log_normalise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b09598",
   "metadata": {},
   "source": [
    "##### Data Augmentation with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606aa091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import expand_dims\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e88c8b",
   "metadata": {},
   "source": [
    "You need to download any image and give its path instead of 'image2.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image with the required shape\n",
    "img_input = load_img('image2.jpeg', target_size=(224, 224))\n",
    "# convert the image to an array\n",
    "img = img_to_array(img_input)\n",
    "# expand dimensions so that it represents a single 'sample'\n",
    "img = expand_dims(img, axis=0)\n",
    "print('Image shape',img.shape)\n",
    "# Displaying the image\n",
    "img_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an image data generator\n",
    "datagenerator = ImageDataGenerator(vertical_flip=True,horizontal_flip=True)\n",
    "# Creating the data iterator\n",
    "dataiterator = datagenerator.flow(img,batch_size=1)\n",
    "for i in range(4):\n",
    "    image = next(dataiterator)[0].astype('uint8')\n",
    "    plt.figure()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226ee5ff",
   "metadata": {},
   "source": [
    "##### Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565453f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an image data generator\n",
    "datagenerator = ImageDataGenerator(width_shift_range=30,height_shift_range=20)\n",
    "# Creating the data iterator\n",
    "dataiterator = datagenerator.flow(img,batch_size=1)\n",
    "for i in range(4):\n",
    "    image = next(dataiterator)[0].astype('uint8')\n",
    "    plt.figure()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c89c767",
   "metadata": {},
   "source": [
    "#### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab82d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for angle in [15,30,45,60,110]:\n",
    "    # Defining an image data generator\n",
    "    datagenerator = ImageDataGenerator(rotation_range = angle)\n",
    "    # Creating the data iterator\n",
    "    dataiterator = datagenerator.flow(img,batch_size=1)\n",
    "    for i in range(1):\n",
    "        image = next(dataiterator)[0].astype('uint8')\n",
    "        plt.figure()\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43117c2a",
   "metadata": {},
   "source": [
    "#### Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an image data generator\n",
    "datagenerator = ImageDataGenerator(brightness_range = (0.3,2))\n",
    "# Creating the data iterator\n",
    "dataiterator = datagenerator.flow(img,batch_size=1)\n",
    "for i in range(5):\n",
    "    image = next(dataiterator)[0].astype('uint8')\n",
    "    plt.figure()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b089b8d",
   "metadata": {},
   "source": [
    "#### Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d86f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an image data generator\n",
    "datagenerator = ImageDataGenerator(zoom_range = (0.3,2))\n",
    "# Creating the data iterator\n",
    "dataiterator = datagenerator.flow(img,batch_size=1)\n",
    "for i in range(4):\n",
    "    image = next(dataiterator)[0].astype('uint8')\n",
    "    plt.figure()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75740ad",
   "metadata": {},
   "source": [
    "#### Monitoring using Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bbc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir '/logs/fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77feb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the TensorBoard callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir 'logs/fit'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee9945b",
   "metadata": {},
   "source": [
    "#### Learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf434f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create a callback to log the learning rate during training\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lambda epoch: 0.01 * (0.1 ** (epoch // 20)))\n",
    "\n",
    "# Create a TensorBoard callback to log the learning rate, accuracy, and loss\n",
    "log_dir = 'logs/fit'\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test),\n",
    "                    callbacks=[lr_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5972264f",
   "metadata": {},
   "source": [
    "#### Model baselining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf710dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b475e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Define the model checkpointing callback\n",
    "checkpoint_path = \"model_checkpoint.h5\"\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, save_best_only=True, save_weights_only=False,\n",
    "    monitor=\"val_loss\", mode=\"min\", verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with early stopping and checkpointing\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=25,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Save the model\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "# Restore the model from a checkpoint\n",
    "loaded_model = keras.models.load_model(\"model_checkpoint.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ba2be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
