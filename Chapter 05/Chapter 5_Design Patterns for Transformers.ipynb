{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df36d118",
   "metadata": {},
   "source": [
    "#### Chapter 5 : Design Patterns for Transformers\n",
    "\n",
    "\n",
    "##### Positional Encoding sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8241e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Function to generate the positional encoding of a sentence\n",
    "def positional_encoding(L, d_model):\n",
    "    pos_enc = np.zeros((L, d_model))\n",
    "    for pos in range(L):\n",
    "        for i in range(d_model):\n",
    "            if i % 2 == 0:\n",
    "                pos_enc[pos, i] = np.sin(pos / 10000**(i/d_model))\n",
    "            else:\n",
    "                pos_enc[pos, i] = np.cos(pos / 10000**((i-1)/d_model))\n",
    "    return pos_enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sentence and generate the positional embedding\n",
    "sentence = \"Hello world\"\n",
    "words = sentence.split()\n",
    "L = len(words)  # length of the sentence\n",
    "d_model = 16  # embedding size\n",
    "\n",
    "pos_enc = positional_encoding(L, d_model)\n",
    "print(pos_enc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542f157",
   "metadata": {},
   "source": [
    "Building positional encoding in the class for Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9dc36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configurations as a dictionary\n",
    "config = {\"seq\" : 64,\n",
    "          \"encode_vocab_size\":2320,\n",
    "          \"decode_vocab_size\":3667,\n",
    "          \"inp_seq_dim\" :15,\n",
    "          \"HL\" : 128\n",
    "          \n",
    "            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to prepare the input data with embedding and positional encoding\n",
    "\n",
    "class InputTransformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, config):\n",
    "        super(InputTransformer, self).__init__()\n",
    "        self.embedding_encode = Embedding(config[\"encode_vocab_size\"], config[\"HL\"])\n",
    "        self.embedding_decode = Embedding(config[\"decode_vocab_size\"], config[\"HL\"])\n",
    "        self.positional_encoding = self.create_positional_encoding(config[\"inp_seq_dim\"], config[\"HL\"])\n",
    "        \n",
    "    def create_positional_encoding(self, max_seq_length, d_model):\n",
    "        position = tf.expand_dims(tf.range(max_seq_length, dtype=tf.float32), axis=1)\n",
    "        div_term = tf.exp(tf.range(0, d_model, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / d_model))\n",
    "        pos_enc = tf.concat([tf.sin(position * div_term), tf.cos(position * div_term)], axis=-1)\n",
    "        pos_enc = tf.expand_dims(pos_enc, axis=0)\n",
    "        return pos_enc\n",
    "    \n",
    "    def call(self, inputs,decode=False):\n",
    "        input_seq = inputs\n",
    "        seq_length = tf.shape(input_seq)[1]\n",
    "        \n",
    "        if decode:\n",
    "            # Embedding\n",
    "            embedded_seq = self.embedding_decode(input_seq)\n",
    "            # Positional Encoding\n",
    "            encoded_seq = embedded_seq + self.positional_encoding[:, :seq_length, :]\n",
    "        else:\n",
    "            # Embedding\n",
    "            embedded_seq = self.embedding_encode(input_seq)\n",
    "            # Positional Encoding\n",
    "            encoded_seq = embedded_seq + self.positional_encoding[:, :seq_length, :]\n",
    "        \n",
    "        return encoded_seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c175e4d",
   "metadata": {},
   "source": [
    "#### Scaled Dot Product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50538ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import math, matmul, reshape, shape, transpose, cast, float32 \n",
    "\n",
    "from tensorflow.keras.layers import Dense, Layer\n",
    "from tensorflow.keras.backend import softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50762eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configurations as a dictionary\n",
    "config = {\"seq\" : 64,\n",
    "          \"encode_vocab_size\":2320,\n",
    "          \"decode_vocab_size\":3667,\n",
    "          \"inp_seq_dim\" :15,\n",
    "          \"HL\" : 128,\n",
    "          \"dim_QKV\" : 64,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled-Dot Product Attention implementation\n",
    "class ScaledDotProdAttn(Layer): \n",
    "    def __init__(self,config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.config = config\n",
    "            \n",
    "    def call(self,Q,K,V,mask=None):\n",
    "        '''\n",
    "        Inputs : Q,K, V of shape > (batch size (bs),Sequence Length (seq), Embedding dimension)\n",
    "        returns : Attention of shape > (bs,seq,dim)\n",
    "        '''\n",
    "        # Calculating the attention scores and then scaling: Shape (bs,seq,dimension) > bs,seq,seq)\n",
    "        Attnscores = matmul(Q,K,transpose_b=True) / math.sqrt(cast(self.config[\"dim_QKV\"], float32))\n",
    "        # Apply mask to the attention scores\n",
    "        if mask is not None: \n",
    "            Attnscores += -1e9 * mask        \n",
    "        # Softmax applied to calculate weighted attention scores\n",
    "        Attnweights = softmax(Attnscores) # Shape (bs,seq,seq)\n",
    "        # Attention computed by multipliying weights with values\n",
    "        Attn = matmul(Attnweights, V) # Shape (bs,seq,dim)\n",
    "        return Attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48e5de7",
   "metadata": {},
   "source": [
    "#### Multihead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf865174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configurations as a dictionary\n",
    "config = {\"seq\" : 64,\n",
    "          \"encode_vocab_size\":2320,\n",
    "          \"decode_vocab_size\":3667,\n",
    "          \"inp_seq_dim\" :15,\n",
    "          \"HL\" : 128,\n",
    "          \"dim_QKV\" : 64,\n",
    "          \"h\":8,\n",
    "          \"HFF\" : 512,\n",
    "          \"prob\" : 0.1,\n",
    "          \"n_layers\":2\n",
    "            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7626eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttn(Layer):\n",
    "    def __init__(self,config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = ScaledDotProdAttn(config) # Scaled dot product attention \n",
    "        self.heads = config[\"h\"] # Number of attention heads\n",
    "        self.d_QKV = config[\"dim_QKV\"] # Dimensionality of the linearly projection of queries,keys and values\n",
    "        self.hl = config[\"HL\"] # Dimensionality of linear layer of the attention model\n",
    "        self.WQ = Dense(self.hl)\n",
    "        self.WK = Dense(self.hl)\n",
    "        self.WV = Dense(self.hl)\n",
    "        # Learned linear projection matrix of the multi-head output\n",
    "        self.WO = Dense(self.hl) \n",
    "    # Method to reshape tensors for multihead attention\n",
    "    def split_heads(self, tensor):\n",
    "        \"\"\"Function for computing attention on several heads simultaneously\n",
    "        Splits embedded dimension >  (num_heads, head_depth).\n",
    "        Transpose the tensor >  (bs, num_heads, ..., head_depth)\n",
    "        \"\"\"\n",
    "        tensor = tf.reshape(tensor, (shape(tensor)[0], shape(tensor)[1],self.heads, -1))\n",
    "        return tf.transpose(tensor, perm=[0, 2, 1, 3]) \n",
    "    def call(self,q,k,v,mask=None):\n",
    "        # Get the linear projection of Queries,keys and values\n",
    "        q = self.WQ(q) # (bs, seq, dim) x (dim, hl) --> (bs, seq, hl)\n",
    "        k = self.WK(k) # --> (bs, seq, hl)\n",
    "        v = self.WV(v) # --> (bs, seq, hl)\n",
    "        # Split the heads of the tensors\n",
    "        Q = self.split_heads(q) # (bs, num_heads, seq, head_depth)\n",
    "        K = self.split_heads(k) # (bs, num_heads, seq, head_depth)\n",
    "        V = self.split_heads(v) # (bs, num_heads, seq, head_depth)\n",
    "        # Calling the Scaled dot product attention\n",
    "        attn = self.attention(Q,K,V,mask) # (bs, num_heads, seq, head_depth)\n",
    "        # Transpose the attnetion\n",
    "        attn = tf.transpose(attn, perm=[0, 2, 1, 3]) \n",
    "        # Reshape the attn \n",
    "        output = tf.reshape(attn, (shape(attn)[0], -1, self.hl))  # (bs, seq, hl)\n",
    "        # Return the linear projection of the output\n",
    "        return self.WO(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0d881",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual + Normalisation Layer\n",
    "class ResidNorm(Layer): \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Layer normalization layer\n",
    "        self.resid_norm = LayerNormalization() \n",
    "    def call(self, x, output):\n",
    "        # The reidual layer which sums up input and output \n",
    "        x = x + output\n",
    "        # Apply layer normalization to the sum\n",
    "        return self.resid_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed forward layer\n",
    "class FeedForward(Layer):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # First fully connected feed forward layer \n",
    "        self.ff1 = Dense(config[\"HFF\"]) \n",
    "        # Second fully connected feed forward layer \n",
    "        self.ff2 = Dense(config[\"HL\"]) \n",
    "        # ReLU activation layer\n",
    "        self.activation = ReLU() \n",
    "    def call(self, x):\n",
    "        # The input is first passed through the feed forward\n",
    "        ff1 = self.ff1(x)\n",
    "        # Activation layer for this output\n",
    "        ac1 = self.activation(ff1)\n",
    "        # Return the second feed forward layer\n",
    "        return self.ff2(ac1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355602cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for a layer of encoder\n",
    "class EncodLayer(Layer):\n",
    "    def __init__(self,config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mha = MultiheadAttn(config)\n",
    "        self.dropout = Dropout(config[\"prob\"])\n",
    "        self.residnorm = ResidNorm()\n",
    "        self.ff = FeedForward(config)\n",
    "    def call(self, x, padd_mask, training):\n",
    "        # Multi-head attention layer\n",
    "        mha_output = self.mha(x, x, x, padd_mask) # shape >  (bs, seq, dim)\n",
    "        # dropout layer\n",
    "        mha_output = self.dropout(mha_output, training=training)\n",
    "        # residual + normalisation layer\n",
    "        residNorm_output = self.residnorm(x, mha_output) # shape >  (bs, seq, dim)\n",
    "        # Fully connected layer\n",
    "        ff_output = self.ff(residNorm_output) # shape >  (bs, seq, dim)\n",
    "        # Second dropout layer\n",
    "        ff_output = self.dropout(ff_output, training=training) \n",
    "        # Second residual + normalisation layer\n",
    "        return self.residnorm(residNorm_output, ff_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Encoder\n",
    "class Encoder(Layer):\n",
    "    def __init__(self, config,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_tran = InputTransformer(config)\n",
    "        self.dropout = Dropout(config[\"prob\"])\n",
    "        self.encoder_layer = [EncodLayer(config) for _ in range(config[\"n_layers\"])]\n",
    "    def call(self, input_seq, padding_mask, training):\n",
    "        # Transform input using positional encoding + embedding layer\n",
    "        input_output = self.input_tran(input_seq) # shape >  (bs, seq, dim)\n",
    "        # Dropout layer\n",
    "        x = self.dropout(input_output, training=training)\n",
    "         # Input with positional encoder is fed into each layer of encoder\n",
    "        for i, layer in enumerate(self.encoder_layer): \n",
    "            x = layer(x, padding_mask, training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5f00b",
   "metadata": {},
   "source": [
    "#### Decoder\n",
    "\n",
    "First building a sample matrix to demostrate masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the matrix size\n",
    "matrix_size = (7,7)\n",
    "# Create a matrix for the decoder input\n",
    "input_matrix = tf.random.normal(matrix_size)\n",
    "input_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79762693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ones matrix\n",
    "ones_matrix = tf.ones(matrix_size)\n",
    "# Create a lower triangle mask\n",
    "lower_triangle_mask = tf.linalg.band_part(ones_matrix, -1, 0)\n",
    "lower_triangle_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef13c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the masked input\n",
    "masked_input = input_matrix * lower_triangle_mask\n",
    "masked_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e4a48",
   "metadata": {},
   "source": [
    "##### Decoder layer and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for a layer of decoder\n",
    "class DecodeLayer(Layer):\n",
    "    def __init__(self,config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mha1 = MultiheadAttn(config)\n",
    "        self.dropout = Dropout(config[\"prob\"])\n",
    "        self.residnorm = ResidNorm()\n",
    "        self.mha2 = MultiheadAttn(config)\n",
    "        self.ff = FeedForward(config)\n",
    "        \n",
    "    def call(self, x,encoder_output, la_mask, padd_mask, training):\n",
    "        # Self Multi-head attention layer\n",
    "        mha1_output = self.mha1(x, x, x, la_mask) # shape >  (bs, seq, dim)\n",
    "        # First dropout layer\n",
    "        mha1_output = self.dropout(mha1_output, training=training)\n",
    "        # First residual + normalisation layer\n",
    "        residNorm1_output = self.residnorm(x, mha1_output) # shape >  (bs, seq, dim)\n",
    "        # Cross Multi-head attention layer\n",
    "        mha2_output = self.mha1(residNorm1_output, encoder_output, encoder_output, padd_mask) # shape >  (bs, seq, dim)\n",
    "        # Second dropout layer\n",
    "        mha2_output = self.dropout(mha2_output, training=training)\n",
    "        # Second residual + normalisation layer\n",
    "        residNorm2_output = self.residnorm(residNorm1_output, mha2_output) # shape >  (bs, seq, dim)\n",
    "        # Fully connected layer\n",
    "        ff_output = self.ff(residNorm2_output) # shape >  (bs, seq, dim)\n",
    "        # Third dropout layer\n",
    "        ff_output = self.dropout(ff_output, training=training) \n",
    "        # Third residual + normalisation layer\n",
    "        return self.residnorm(residNorm2_output, ff_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb896c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Decoder\n",
    "class Decoder(Layer):\n",
    "    def __init__(self, config,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_tran = InputTransformer(config)\n",
    "        self.dropout = Dropout(config[\"prob\"])\n",
    "        self.decoder_layer = [DecodeLayer(config) for _ in range(config[\"n_layers\"])]\n",
    "    def call(self,target_output, encoder_output, la_mask, padd_mask,training):\n",
    "        # Transform input using positional encoding + embedding layer\n",
    "        target_transformed = self.input_tran(target_output,True) # shape >  (bs, seq, dim)\n",
    "        # Dropout layer\n",
    "        x = self.dropout(target_transformed, training=training)\n",
    "         # Input with positional encoder is fed into each layer of encoder\n",
    "        for i, layer in enumerate(self.decoder_layer): \n",
    "            x = layer(x, encoder_output, la_mask, padd_mask, training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5aa2f",
   "metadata": {},
   "source": [
    "#### Complete transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede1b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(self, inputs):\n",
    "        mask = tf.math.equal(inputs, 0)  # shape: (batch_size, seq_length)\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        mask = tf.expand_dims(tf.expand_dims(mask, axis=1), axis=1)  # shape: (batch_size, 1, 1, seq_length)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the look ahead mask\n",
    "def create_look_ahead_mask(size):\n",
    "    # Create a matrix of ones with shape (size, size)\n",
    "    mask = tf.ones((size, size))\n",
    "    # Set the upper triangular region to 1\n",
    "    mask = 1- tf.linalg.band_part(mask, -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(Model):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super(TransformerModel, self).__init__(**kwargs)\n",
    "        # Initialise the encoder, decoder and the final dense layers\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config)\n",
    "        self.denseLayer = Dense(config[\"decode_vocab_size\"])\n",
    "    ##################################################################\n",
    "    # Create the padding mask \n",
    "    def create_padding_mask(self, inputs):\n",
    "        mask = tf.math.equal(inputs, 0)  # shape: (batch_size, seq_length)\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        mask = tf.expand_dims(tf.expand_dims(mask, axis=1), axis=1)  # shape: (batch_size, 1, 1, seq_length)\n",
    "        return mask\n",
    "    # Create the look ahead mask\n",
    "    def create_look_ahead_mask(self, size):\n",
    "        mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "        return mask\n",
    "    #############################################################\n",
    "    # The call method for the transformer\n",
    "    def call(self, encoder_input, decoder_input, training):\n",
    "        # Create both masks\n",
    "        enc_pad_mask = self.create_padding_mask(encoder_input)\n",
    "        dec_look_ahead_mask = self.create_look_ahead_mask(decoder_input.shape[1])\n",
    "        # Generate Encoder and Decoder multihead attention output\n",
    "        encoder_output = self.encoder(encoder_input, enc_pad_mask, training)\n",
    "        decoder_output = self.decoder(decoder_input, encoder_output, dec_look_ahead_mask, enc_pad_mask, training)\n",
    "        # Final Dense layer for the decoder output\n",
    "        trans_output = self.denseLayer(decoder_output)\n",
    "        return trans_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb25470",
   "metadata": {},
   "source": [
    "##### Training the transformer model\n",
    "\n",
    "The data has to be downloaded from the below link and saved in your local machine\n",
    "\n",
    "https://github.com/Rishav09/Neural-Machine-Translation-System/blob/master/english-german-both.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ba7d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "# Define the path to the data\n",
    "dataPath = \"data/english-german-both.pkl\"\n",
    "# Load the data using pickle\n",
    "raw_dataset = load(open(dataPath, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a074c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include start and end of string tokens\n",
    "for i in range(raw_dataset[:, 0].size):\n",
    "    raw_dataset[i, 0] = \"<START> \" + raw_dataset[i, 0] + \" <EOS>\"\n",
    "    raw_dataset[i, 1] = \"<START> \" + raw_dataset[i, 1] + \" <EOS>”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854317be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a tokenizer\n",
    "def create_tokenizer(dataset): \n",
    "\n",
    "    tokenizer = Tokenizer() \n",
    "\n",
    "    tokenizer.fit_on_texts(dataset)\n",
    "    return tokenizer\n",
    "# Find the sequence length\n",
    "def find_seq_length(dataset):\n",
    "    return max(len(seq.split()) for seq in dataset)\n",
    "# Find the vocabulary size\n",
    "def find_vocab_size(tokenizer, dataset):\n",
    "    tokenizer.fit_on_texts(dataset)\n",
    "    return len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random shuffle the dataset\n",
    "shuffle(raw_dataset)\n",
    "# Split into train and validation sets\n",
    "train_split = 0.9\n",
    "train = raw_dataset[:int(raw_dataset[:,0].shape * train_split)]\n",
    "val = raw_dataset[int(raw_dataset[:,0].shape * train_split) : ]\n",
    "\n",
    "# Prepare tokenizer for the encoder \n",
    "\n",
    "enc_tokenizer = create_tokenizer(train[:, 0])\n",
    "enc_seq_length = find_seq_length(train[:, 0])\n",
    "enc_vocab_size = find_vocab_size(enc_tokenizer, train[:, 0])\n",
    "\n",
    "# Prepare tokenizer for the decoder \n",
    "\n",
    "dec_tokenizer = create_tokenizer(train[:, 1])\n",
    "dec_seq_length = find_seq_length(train[:, 1])\n",
    "dec_vocab_size = find_vocab_size(dec_tokenizer, train[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and pad the encoder sequences\n",
    "trainX = enc_tokenizer.texts_to_sequences(train[:, 0])\n",
    "trainX = pad_sequences(trainX, maxlen=enc_seq_length, padding=‘post')\n",
    "\n",
    "# Encode and pad the decoder sequences\n",
    "trainY = dec_tokenizer.texts_to_sequences(train[:, 1])\n",
    "trainY = pad_sequences(trainY, maxlen=dec_seq_length, padding=‘post')\n",
    "\n",
    "# Converting the data set to tensors\n",
    "\n",
    "trainX = convert_to_tensor(trainX, dtype=int64)\n",
    "trainY = convert_to_tensor(trainY, dtype=int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# Training data set\n",
    "train_dataset = data.Dataset.from_tensor_slices((trainX, trainY[:,:-1],trainY[:,1:])).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "# Custom scheduler for the optimizer\n",
    "class LRScheduler(LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the optimiser\n",
    "optimizer = tf.keras.optimizers.Adam(LRScheduler(config[\"HL\"]), beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked loss function \n",
    "def masked_loss(label, pred):\n",
    "    mask = label != 0\n",
    "    loss = sparse_categorical_crossentropy(label, pred,from_logits=True)\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "\n",
    "# Maked accuracy function\n",
    "def masked_accuracy(label, pred):\n",
    "    # Create mask so that the zero padding values are not included in the computation of accuracy\n",
    "    mask = label != 0\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "    match = match & mask\n",
    "\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f5c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import data, train, math, reduce_sum, cast, equal, argmax,float32, GradientTape, TensorSpec, function, int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function\n",
    "def train_step(encoder_input, decoder_input, decoder_output): \n",
    "    with GradientTape() as tape:\n",
    "        # Run the forward pass of the model to generate a prediction\n",
    "        prediction = train_model(encoder_input, decoder_input, training=True) \n",
    "        # Compute the training loss\n",
    "        #loss = loss_fcn(decoder_output, prediction) \n",
    "        loss = masked_loss(decoder_output, prediction) \n",
    "        # Compute the training accuracy\n",
    "        #accuracy = accuracy_fcn(decoder_output, prediction)\n",
    "        accuracy = masked_accuracy(decoder_output, prediction)\n",
    "        # Retrieve gradients of the trainable variables with respect to the training loss\n",
    "    gradients = tape.gradient(loss, train_model.trainable_weights) \n",
    "    # Update the values of the trainable variables by gradient descent\n",
    "    optimizer.apply_gradients(zip(gradients, train_model.trainable_weights))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadabc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the metrics for monitoring\n",
    "train_loss = Mean(name='train_loss')\n",
    "train_accuracy = Mean(name='train_accuracy')\n",
    "\n",
    "# Instantiate the transformer model\n",
    "train_model = TransformerModel(config)\n",
    "\n",
    "# Start the training \n",
    "epochs = 10\n",
    "for epoch in range(epochs): \n",
    "    train_loss.reset_states() \n",
    "    train_accuracy.reset_states()\n",
    "    print(\"\\nStart of epoch %d\" % (epoch + 1)) \n",
    "    start_time = time()\n",
    "    for step, (encoder_input,decoder_input,decoder_output) in enumerate(train_dataset):\n",
    "        train_step(encoder_input, decoder_input, decoder_output)\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1} Step {step} Loss {train_loss.result():.3f} \"\n",
    "            + f\"Accuracy {train_accuracy.result():.3f}\")\n",
    "    # Print epoch number and loss value at the end of every epoch\n",
    "    print(f\"Epoch {epoch+1}: Training Loss {train_loss.result():.4f}, \" + f\"Training Accuracy {train_accuracy.result():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106a0093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ad4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
